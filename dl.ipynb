{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d54d356-bf62-4c4c-85af-0ade17ce59c6",
   "metadata": {},
   "source": [
    "# Up and going with tf( version 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f1165-d24f-4ef4-b2e4-37159c42f78f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "040b7d28-fb0a-4987-9e40-d8bd722700d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 12:58:45.384006: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-07 12:58:45.424858: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9ff98-86ba-4d9a-8c9a-43428697304a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f3e3b9-3496-4d42-acd2-fc989861c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_eager_execution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6f0eeb-4378-47be-a58d-40f1095803fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3,name='x')\n",
    "y = tf.Variable(8,name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac98e0f-a57a-4466-8c80-ad7c87f78a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x*x*y + y + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8fe634-b9f3-4128-82c6-ac4a19b73a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9107a47c-8396-4291-b041-03385fc7bcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 21:45:09.051701: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "sess.run(x.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd745e88-a9f1-42ab-a563-feb14a8bcb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(y.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dba030ac-1364-4435-b6df-f18a2cde5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sess.run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd4e7b0d-3f3d-4efe-a354-452616604803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03cda6d7-6a4a-4cc9-aa49-d74464eee822",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1f2bbf6-9c3f-4bb1-a188-81bb119979c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    res = sess.run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dca3a6c0-1eb0-4407-865a-f1f5dc6877b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344f3507-49c6-4cce-8908-83b093afaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    res = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d0c1f56-66f3-40b8-aa54-c0a49e6dd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    res = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe05635-80a3-42fc-a225-661190a6996a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f258b8-ee04-4068-85bd-778cb315cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.Variable(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57d18ffa-ccfa-443b-8950-582b6e8bc652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7f32bbbab880>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36a7127f-a2cf-4284-ab92-6fe79fcf6c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7f32bbbab880>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94dc0441-c4d9-425e-9250-36496faa2dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2405b353-a66d-4c94-8776-1a07ffa3e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0581d11-c4bd-4638-a0b8-78c8fd1eaad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6e53b1b-94df-4093-bd94-1a4d97b5aa2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d175460-0e30-48be-9280-e4a607b230fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b5c33f9-1c42-4bb2-b2d0-83c080fa33ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val) # 10\n",
    "    print(z_val) # 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49c0d83-c87d-4ada-9e2e-839e888b1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = numpy.c_[numpy.ones((m, 1)), housing.data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5315d5fd-49dc-41ca-bee6-5676797e5e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13fc7a76-1bcd-478d-adbe-330970ff1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "391ca47d-5e1d-4ba0-b97a-14939e4cce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_housing_data_plus_bias = housing_data_plus_bias.copy()\n",
    "means,stds = housing_data_plus_bias[:,1:].mean(axis=0),housing_data_plus_bias[:,1:].std(axis=0)\n",
    "scaled_housing_data_plus_bias[:,1:] -= means\n",
    "scaled_housing_data_plus_bias[:,1:] /= stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be595161-54ef-46ec-854b-2256fc7a8719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 7.565616\n",
      "Epoch 100 MSE = 7.2847657\n",
      "Epoch 200 MSE = 7.016872\n",
      "Epoch 300 MSE = 6.7612643\n",
      "Epoch 400 MSE = 6.517311\n",
      "Epoch 500 MSE = 6.2844157\n",
      "Epoch 600 MSE = 6.0620193\n",
      "Epoch 700 MSE = 5.8495903\n",
      "Epoch 800 MSE = 5.64663\n",
      "Epoch 900 MSE = 5.452666\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            sess.run(training_op)\n",
    "            best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a1f8df9-910c-4581-b004-1c29b323877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.placeholder(tf.float32,shape=(None,3))\n",
    "B = A +5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    B1 = B.eval(feed_dict={A:[[1,2,3],[7,8,9]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c38457a9-b614-45c6-8f92-bb9083a038f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.,  7.,  8.],\n",
       "       [12., 13., 14.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f3269-f504-44fb-bd45-d59a31d8f6b9",
   "metadata": {},
   "source": [
    "# Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ebd0b-db42-48a1-bd9c-adc0557aadce",
   "metadata": {},
   "source": [
    "## Unscaled data( Exploding Gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73ec8810-4501-4bfb-903c-767252a8a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_mini_batch(ix,size):\n",
    "    ix   = slice(size*ix,size*(ix+1))\n",
    "    data = lambda : fetch_california_housing()\n",
    "    y = data().target[ix].reshape(-1,1)\n",
    "    X = data().data[ix,:]\n",
    "    bias = numpy.ones((min(size,len(X)), 1))\n",
    "    X = numpy.c_[bias, X]\n",
    "    return y,X     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89a68538-a540-4c25-96b5-2d3a98918ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[2.697],\n",
       "         [2.992],\n",
       "         [2.414],\n",
       "         [2.267],\n",
       "         [2.611]]),\n",
       "  array([[ 1.00000000e+00,  4.03680000e+00,  5.20000000e+01,\n",
       "           4.76165803e+00,  1.10362694e+00,  4.13000000e+02,\n",
       "           2.13989637e+00,  3.78500000e+01, -1.22250000e+02],\n",
       "         [ 1.00000000e+00,  3.65910000e+00,  5.20000000e+01,\n",
       "           4.93190661e+00,  9.51361868e-01,  1.09400000e+03,\n",
       "           2.12840467e+00,  3.78400000e+01, -1.22250000e+02],\n",
       "         [ 1.00000000e+00,  3.12000000e+00,  5.20000000e+01,\n",
       "           4.79752705e+00,  1.06182380e+00,  1.15700000e+03,\n",
       "           1.78825348e+00,  3.78400000e+01, -1.22250000e+02],\n",
       "         [ 1.00000000e+00,  2.08040000e+00,  4.20000000e+01,\n",
       "           4.29411765e+00,  1.11764706e+00,  1.20600000e+03,\n",
       "           2.02689076e+00,  3.78400000e+01, -1.22260000e+02],\n",
       "         [ 1.00000000e+00,  3.69120000e+00,  5.20000000e+01,\n",
       "           4.97058824e+00,  9.90196078e-01,  1.55100000e+03,\n",
       "           2.17226891e+00,  3.78400000e+01, -1.22250000e+02]])),\n",
       " (5, 1),\n",
       " (5, 9))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r:=fetch_mini_batch(1,5),r[0].shape,r[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05e200d3-b1ab-4225-ab77-5b26b31e86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "n_batches  = int(numpy.ceil(m/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0be4a0db-9df7-48d9-be18-3dfec8bae0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32,shape=(None,1),name='y')\n",
    "X = tf.placeholder(tf.float32,shape=(None,n+1),name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8c9cb0b-60b9-490e-a3a5-82fd84d8c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7149068-ded3-4fdd-be8c-cf089458f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "θ = tf.Variable(numpy.zeros((n+1,1),dtype='float32'),name='Theta')\n",
    "yhat = tf.matmul(X,θ,name='predictions')\n",
    "\n",
    "ε = yhat - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(ε),name='mse')\n",
    "\n",
    "gradients = (2/m)*tf.matmul(tf.transpose(X),ε)\n",
    "\n",
    "trainop = tf.assign(θ,θ-lr*gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c68ff2af-c41b-464a-817e-13720ae60d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = nan\n",
      "Epoch 100 MSE = nan\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_ix in range(n_batches):\n",
    "            y_batch,X_batch = fetch_mini_batch(batch_ix,batch_size)\n",
    "            sess.run(trainop,feed_dict={y:y_batch,X:X_batch})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={y:y_batch,X:X_batch}))\n",
    "    best_theta = θ.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07a39e-7dac-443a-8b12-e10be3282a3e",
   "metadata": {},
   "source": [
    "## Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba81186e-6115-442d-ac58-ea73c4060c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_mini_batch(ix,size):\n",
    "    ix   = slice(size*ix,size*(ix+1))\n",
    "    data = lambda : fetch_california_housing()\n",
    "    y = data().target[ix].reshape(-1,1)\n",
    "    X = (data().data[ix,:]-means)/stds\n",
    "    bias = numpy.ones((min(size,len(X)), 1))\n",
    "    X = numpy.c_[bias, X]\n",
    "    return y,X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe110c9d-6734-410f-a5f9-a5de5e24ac4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "θ = tf.Variable(numpy.zeros((n+1,1),dtype='float32'),name='Theta')\n",
    "yhat = tf.matmul(X,θ,name='predictions')\n",
    "\n",
    "ε = yhat - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(ε),name='mse')\n",
    "\n",
    "gradients = (2/m)*tf.matmul(tf.transpose(X),ε)\n",
    "\n",
    "trainop = tf.assign(θ,θ-lr*gradients)\n",
    "\n",
    "n_epochs = 1000\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver() #saving sessions\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for batch_ix in range(n_batches):\n",
    "            \n",
    "            y_batch,X_batch = fetch_mini_batch(batch_ix,batch_size)\n",
    "            \n",
    "            sess.run(trainop,feed_dict={y:y_batch,X:X_batch})\n",
    "            \n",
    "        if epoch % 100 == 0:\n",
    "                saver.save(sess,f\"models/model.ckpt\")\n",
    "                print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={y:y_batch,X:X_batch}))\n",
    "    bestθ = θ.eval()\n",
    "    saver.save(sess,f\"models/modelfinal.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a081b3-23cc-4f1a-b88e-9e638ab46332",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestθ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658984b-20ae-4420-a936-6dd6c3a3ffc7",
   "metadata": {},
   "source": [
    "# Visializing with tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d90a28e-ca3b-48b0-b51b-07c0d623c57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_logs/run-2024-02-07-12-55-45/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "logd = f'tf_logs/run-{now}/'\n",
    "logd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ecd2959-4da1-4134-9069-e4f2734230d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    y = tf.placeholder(tf.float32,shape=(None,1),name='y')\n",
    "    X = tf.placeholder(tf.float32,shape=(None,n+1),name='X')\n",
    "    \n",
    "    θ = tf.Variable(numpy.zeros((n+1,1),dtype='float32'),name='Theta')\n",
    "    yhat = tf.matmul(X,θ,name='predictions')\n",
    "    \n",
    "    ε = yhat - y\n",
    "    \n",
    "    mse = tf.reduce_mean(tf.square(ε),name='mse')\n",
    "    \n",
    "    gradients = (2/m)*tf.matmul(tf.transpose(X),ε) \n",
    "    \n",
    "    trainop = tf.assign(θ,θ-lr*gradients)\n",
    "    \n",
    "    n_epochs = 1000\n",
    "    init = tf.global_variables_initializer()\n",
    "        \n",
    "    mse_summary = tf.summary.scalar('mse',mse)\n",
    "    \n",
    "\n",
    "    file_writer = tf.summary.FileWriter(logd,graph=graph)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            for batch_ix in range(n_batches):\n",
    "                \n",
    "                y_batch,X_batch = fetch_mini_batch(batch_ix,batch_size)\n",
    "                \n",
    "                sess.run(trainop,feed_dict={y:y_batch,X:X_batch})\n",
    "                \n",
    "                summary = mse_summary.eval(feed_dict={y:y_batch,X:X_batch})\n",
    "                \n",
    "                file_writer.add_summary(summary,epoch*batch_ix)\n",
    "\n",
    "        \n",
    "        bestθ = θ.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32437d87-f867-4cf7-9a4d-befd9e5eb57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package tensorflow._api.v2.compat.v1.summary in tensorflow._api.v2.compat.v1:\n",
      "\n",
      "NAME\n",
      "    tensorflow._api.v2.compat.v1.summary - Public API for tf._api.v2.summary namespace\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        tensorflow.python.summary.writer.writer_cache.FileWriterCache\n",
      "    google._upb._message.Message(builtins.object)\n",
      "        tensorflow.core.framework.summary_pb2.Summary(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.SummaryDescription(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.Event(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.SessionLog(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.TaggedRunMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "    google.protobuf.message.Message(builtins.object)\n",
      "        tensorflow.core.framework.summary_pb2.Summary(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.SummaryDescription(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.Event(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.SessionLog(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.TaggedRunMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "    tensorflow.python.summary.writer.writer.SummaryToEventTransformer(builtins.object)\n",
      "        tensorflow.python.summary.writer.writer.FileWriter\n",
      "    \n",
      "    class Event(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      Event\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  CopyFrom(self, other_msg)\n",
      "     |      Copies the content of the specified message into the current message.\n",
      "     |      \n",
      "     |      The method clears the current message and then merges the specified\n",
      "     |      message using MergeFrom.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other_msg (Message): A message to copy into the current one.\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo=None)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class FileWriter(SummaryToEventTransformer)\n",
      "     |  FileWriter(logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None, filename_suffix=None, session=None)\n",
      "     |  \n",
      "     |  Writes `Summary` protocol buffers to event files.\n",
      "     |  \n",
      "     |  The `FileWriter` class provides a mechanism to create an event file in a\n",
      "     |  given directory and add summaries and events to it. The class updates the\n",
      "     |  file contents asynchronously. This allows a training program to call methods\n",
      "     |  to add data to the file directly from the training loop, without slowing down\n",
      "     |  training.\n",
      "     |  \n",
      "     |  When constructed with a `tf.compat.v1.Session` parameter, a `FileWriter`\n",
      "     |  instead forms a compatibility layer over new graph-based summaries\n",
      "     |  to facilitate the use of new summary writing with\n",
      "     |  pre-existing code that expects a `FileWriter` instance.\n",
      "     |  \n",
      "     |  This class is not thread-safe.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  This API is not compatible with eager execution or `tf.function`. To migrate\n",
      "     |  to TF2, please use `tf.summary.create_file_writer` instead for summary\n",
      "     |  management. To specify the summary step, you can manage the context with\n",
      "     |  `tf.summary.SummaryWriter`, which is returned by\n",
      "     |  `tf.summary.create_file_writer()`. Or, you can also use the `step` argument\n",
      "     |  of summary functions such as `tf.summary.histogram`.\n",
      "     |  See the usage example shown below.\n",
      "     |  \n",
      "     |  For a comprehensive `tf.summary` migration guide, please follow\n",
      "     |  [Migrating tf.summary usage to\n",
      "     |  TF 2.0](https://www.tensorflow.org/tensorboard/migrate#in_tf_1x).\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name        | TF2 Arg Name    | Note                              |\n",
      "     |  | :---------------- | :---------------- | :-------------------------------- |\n",
      "     |  | `logdir`          | `logdir`          | -                                 |\n",
      "     |  | `graph`           | Not supported     | -                                 |\n",
      "     |  | `max_queue`       | `max_queue`       | -                                 |\n",
      "     |  | `flush_secs`      | `flush_millis`    | The unit of time is changed       |\n",
      "     |  :                     :                 : from seconds to milliseconds.     :\n",
      "     |  | `graph_def`       | Not supported     | -                                 |\n",
      "     |  | `filename_suffix` | `filename_suffix` | -                                 |\n",
      "     |  | `name`            | `name`            | -                                 |\n",
      "     |  \n",
      "     |  #### TF1 & TF2 Usage Example\n",
      "     |  \n",
      "     |  TF1:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  dist = tf.compat.v1.placeholder(tf.float32, [100])\n",
      "     |  tf.compat.v1.summary.histogram(name=\"distribution\", values=dist)\n",
      "     |  writer = tf.compat.v1.summary.FileWriter(\"/tmp/tf1_summary_example\")\n",
      "     |  summaries = tf.compat.v1.summary.merge_all()\n",
      "     |  \n",
      "     |  sess = tf.compat.v1.Session()\n",
      "     |  for step in range(100):\n",
      "     |    mean_moving_normal = np.random.normal(loc=step, scale=1, size=[100])\n",
      "     |    summ = sess.run(summaries, feed_dict={dist: mean_moving_normal})\n",
      "     |    writer.add_summary(summ, global_step=step)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  TF2:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  writer = tf.summary.create_file_writer(\"/tmp/tf2_summary_example\")\n",
      "     |  for step in range(100):\n",
      "     |    mean_moving_normal = np.random.normal(loc=step, scale=1, size=[100])\n",
      "     |    with writer.as_default(step=step):\n",
      "     |      tf.summary.histogram(name='distribution', data=mean_moving_normal)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FileWriter\n",
      "     |      SummaryToEventTransformer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      Make usable with \"with\" statement.\n",
      "     |  \n",
      "     |  __exit__(self, unused_type, unused_value, unused_traceback)\n",
      "     |      Make usable with \"with\" statement.\n",
      "     |  \n",
      "     |  __init__(self, logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None, filename_suffix=None, session=None)\n",
      "     |      Creates a `FileWriter`, optionally shared within the given session.\n",
      "     |      \n",
      "     |      Typically, constructing a file writer creates a new event file in `logdir`.\n",
      "     |      This event file will contain `Event` protocol buffers constructed when you\n",
      "     |      call one of the following functions: `add_summary()`, `add_session_log()`,\n",
      "     |      `add_event()`, or `add_graph()`.\n",
      "     |      \n",
      "     |      If you pass a `Graph` to the constructor it is added to\n",
      "     |      the event file. (This is equivalent to calling `add_graph()` later).\n",
      "     |      \n",
      "     |      TensorBoard will pick the graph from the file and display it graphically so\n",
      "     |      you can interactively explore the graph you built. You will usually pass\n",
      "     |      the graph from the session in which you launched it:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      ...create a graph...\n",
      "     |      # Launch the graph in a session.\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      # Create a summary writer, add the 'graph' to the event file.\n",
      "     |      writer = tf.compat.v1.summary.FileWriter(<some-directory>, sess.graph)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The `session` argument to the constructor makes the returned `FileWriter` a\n",
      "     |      compatibility layer over new graph-based summaries (`tf.summary`).\n",
      "     |      Crucially, this means the underlying writer resource and events file will\n",
      "     |      be shared with any other `FileWriter` using the same `session` and `logdir`.\n",
      "     |      In either case, ops will be added to `session.graph` to control the\n",
      "     |      underlying file writer resource.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        logdir: A string. Directory where event file will be written.\n",
      "     |        graph: A `Graph` object, such as `sess.graph`.\n",
      "     |        max_queue: Integer. Size of the queue for pending events and summaries.\n",
      "     |        flush_secs: Number. How often, in seconds, to flush the\n",
      "     |          pending events and summaries to disk.\n",
      "     |        graph_def: DEPRECATED: Use the `graph` argument instead.\n",
      "     |        filename_suffix: A string. Every event file's name is suffixed with\n",
      "     |          `suffix`.\n",
      "     |        session: A `tf.compat.v1.Session` object. See details above.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called with eager execution enabled.\n",
      "     |      \n",
      "     |      @compatibility(eager)\n",
      "     |        `v1.summary.FileWriter` is not compatible with eager execution.\n",
      "     |        To write TensorBoard summaries under eager execution,\n",
      "     |        use `tf.summary.create_file_writer` or\n",
      "     |        a `with v1.Graph().as_default():` context.\n",
      "     |      @end_compatibility\n",
      "     |  \n",
      "     |  add_event(self, event)\n",
      "     |      Adds an event to the event file.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        event: An `Event` protocol buffer.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Flushes the event file to disk and close the file.\n",
      "     |      \n",
      "     |      Call this method when you do not need the summary writer anymore.\n",
      "     |  \n",
      "     |  flush(self)\n",
      "     |      Flushes the event file to disk.\n",
      "     |      \n",
      "     |      Call this method to make sure that all pending events have been written to\n",
      "     |      disk.\n",
      "     |  \n",
      "     |  get_logdir(self)\n",
      "     |      Returns the directory where event file will be written.\n",
      "     |  \n",
      "     |  reopen(self)\n",
      "     |      Reopens the EventFileWriter.\n",
      "     |      \n",
      "     |      Can be called after `close()` to add more events in the same directory.\n",
      "     |      The events will go into a new events file.\n",
      "     |      \n",
      "     |      Does nothing if the EventFileWriter was not closed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from SummaryToEventTransformer:\n",
      "     |  \n",
      "     |  add_graph(self, graph, global_step=None, graph_def=None)\n",
      "     |      Adds a `Graph` to the event file.\n",
      "     |      \n",
      "     |      The graph described by the protocol buffer will be displayed by\n",
      "     |      TensorBoard. Most users pass a graph in the constructor instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        graph: A `Graph` object, such as `sess.graph`.\n",
      "     |        global_step: Number. Optional global step counter to record with the\n",
      "     |          graph.\n",
      "     |        graph_def: DEPRECATED. Use the `graph` parameter instead.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If both graph and graph_def are passed to the method.\n",
      "     |  \n",
      "     |  add_meta_graph(self, meta_graph_def, global_step=None)\n",
      "     |      Adds a `MetaGraphDef` to the event file.\n",
      "     |      \n",
      "     |      The `MetaGraphDef` allows running the given graph via\n",
      "     |      `saver.import_meta_graph()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        meta_graph_def: A `MetaGraphDef` object, often as returned by\n",
      "     |          `saver.export_meta_graph()`.\n",
      "     |        global_step: Number. Optional global step counter to record with the\n",
      "     |          graph.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If both `meta_graph_def` is not an instance of `MetaGraphDef`.\n",
      "     |  \n",
      "     |  add_run_metadata(self, run_metadata, tag, global_step=None)\n",
      "     |      Adds a metadata information for a single session.run() call.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        run_metadata: A `RunMetadata` protobuf object.\n",
      "     |        tag: The tag name for this metadata.\n",
      "     |        global_step: Number. Optional global step counter to record with the\n",
      "     |          StepStats.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If the provided tag was already used for this type of event.\n",
      "     |  \n",
      "     |  add_session_log(self, session_log, global_step=None)\n",
      "     |      Adds a `SessionLog` protocol buffer to the event file.\n",
      "     |      \n",
      "     |      This method wraps the provided session in an `Event` protocol buffer\n",
      "     |      and adds it to the event file.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        session_log: A `SessionLog` protocol buffer.\n",
      "     |        global_step: Number. Optional global step value to record with the\n",
      "     |          summary.\n",
      "     |  \n",
      "     |  add_summary(self, summary, global_step=None)\n",
      "     |      Adds a `Summary` protocol buffer to the event file.\n",
      "     |      \n",
      "     |      This method wraps the provided summary in an `Event` protocol buffer\n",
      "     |      and adds it to the event file.\n",
      "     |      \n",
      "     |      You can pass the result of evaluating any summary op, using\n",
      "     |      `tf.Session.run` or\n",
      "     |      `tf.Tensor.eval`, to this\n",
      "     |      function. Alternatively, you can pass a `tf.compat.v1.Summary` protocol\n",
      "     |      buffer that you populate with your own data. The latter is\n",
      "     |      commonly done to report evaluation results in event files.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        summary: A `Summary` protocol buffer, optionally serialized as a string.\n",
      "     |        global_step: Number. Optional global step value to record with the\n",
      "     |          summary.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from SummaryToEventTransformer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class FileWriterCache(builtins.object)\n",
      "     |  Cache for file writers.\n",
      "     |  \n",
      "     |  This class caches file writers, one per directory.\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  clear()\n",
      "     |      Clear cached summary writers. Currently only used for unit tests.\n",
      "     |  \n",
      "     |  get(logdir)\n",
      "     |      Returns the FileWriter for the specified directory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        logdir: str, name of the directory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `FileWriter`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class SessionLog(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      SessionLog\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  CopyFrom(self, other_msg)\n",
      "     |      Copies the content of the specified message into the current message.\n",
      "     |      \n",
      "     |      The method clears the current message and then merges the specified\n",
      "     |      message using MergeFrom.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other_msg (Message): A message to copy into the current one.\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo=None)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class Summary(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      Summary\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Audio = <class 'tensorflow.core.framework.summary_pb2.Audio'>\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  Image = <class 'tensorflow.core.framework.summary_pb2.Image'>\n",
      "     |  \n",
      "     |  Value = <class 'tensorflow.core.framework.summary_pb2.Value'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  CopyFrom(self, other_msg)\n",
      "     |      Copies the content of the specified message into the current message.\n",
      "     |      \n",
      "     |      The method clears the current message and then merges the specified\n",
      "     |      message using MergeFrom.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other_msg (Message): A message to copy into the current one.\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo=None)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class SummaryDescription(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      SummaryDescription\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  CopyFrom(self, other_msg)\n",
      "     |      Copies the content of the specified message into the current message.\n",
      "     |      \n",
      "     |      The method clears the current message and then merges the specified\n",
      "     |      message using MergeFrom.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other_msg (Message): A message to copy into the current one.\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo=None)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class TaggedRunMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      TaggedRunMetadata\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  CopyFrom(self, other_msg)\n",
      "     |      Copies the content of the specified message into the current message.\n",
      "     |      \n",
      "     |      The method clears the current message and then merges the specified\n",
      "     |      message using MergeFrom.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other_msg (Message): A message to copy into the current one.\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo=None)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "\n",
      "FUNCTIONS\n",
      "    all_v2_summary_ops()\n",
      "        Returns all V2-style summary ops defined in the current default graph.\n",
      "        \n",
      "        This includes ops from TF 2.0 tf.summary and TF 1.x tf.contrib.summary (except\n",
      "        for `tf.contrib.summary.graph` and `tf.contrib.summary.import_event`), but\n",
      "        does *not* include TF 1.x tf.summary ops.\n",
      "        \n",
      "        Returns:\n",
      "          List of summary ops, or None if called under eager execution.\n",
      "    \n",
      "    audio(name, tensor, sample_rate, max_outputs=3, collections=None, family=None)\n",
      "        Outputs a `Summary` protocol buffer with audio.\n",
      "        \n",
      "        The summary has up to `max_outputs` summary values containing audio. The\n",
      "        audio is built from `tensor` which must be 3-D with shape `[batch_size,\n",
      "        frames, channels]` or 2-D with shape `[batch_size, frames]`. The values are\n",
      "        assumed to be in the range of `[-1.0, 1.0]` with a sample rate of\n",
      "        `sample_rate`.\n",
      "        \n",
      "        The `tag` in the outputted Summary.Value protobufs is generated based on the\n",
      "        name, with a suffix depending on the max_outputs setting:\n",
      "        \n",
      "        *  If `max_outputs` is 1, the summary value tag is '*name*/audio'.\n",
      "        *  If `max_outputs` is greater than 1, the summary value tags are\n",
      "           generated sequentially as '*name*/audio/0', '*name*/audio/1', etc\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the generated node. Will also serve as a series name in\n",
      "            TensorBoard.\n",
      "          tensor: A 3-D `float32` `Tensor` of shape `[batch_size, frames, channels]`\n",
      "            or a 2-D `float32` `Tensor` of shape `[batch_size, frames]`.\n",
      "          sample_rate: A Scalar `float32` `Tensor` indicating the sample rate of the\n",
      "            signal in hertz.\n",
      "          max_outputs: Max number of batch elements to generate audio for.\n",
      "          collections: Optional list of ops.GraphKeys.  The collections to add the\n",
      "            summary to.  Defaults to [_ops.GraphKeys.SUMMARIES]\n",
      "          family: Optional; if provided, used as the prefix of the summary tag name,\n",
      "            which controls the tab name used for display on Tensorboard.\n",
      "        \n",
      "        Returns:\n",
      "          A scalar `Tensor` of type `string`. The serialized `Summary` protocol\n",
      "          buffer.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        For compatibility purposes, when invoked in TF2 where the outermost context is\n",
      "        eager mode, this API will check if there is a suitable TF2 summary writer\n",
      "        context available, and if so will forward this call to that writer instead. A\n",
      "        \"suitable\" writer context means that the writer is set as the default writer,\n",
      "        and there is an associated non-empty value for `step` (see\n",
      "        `tf.summary.SummaryWriter.as_default`, `tf.summary.experimental.set_step` or\n",
      "        alternatively `tf.compat.v1.train.create_global_step`). For the forwarded\n",
      "        call, the arguments here will be passed to the TF2 implementation of\n",
      "        `tf.summary.audio`, and the return value will be an empty bytestring tensor,\n",
      "        to avoid duplicate summary writing. This forwarding is best-effort and not all\n",
      "        arguments will be preserved. Additionally:\n",
      "        \n",
      "        * The TF2 op just outputs the data under a single tag that contains multiple\n",
      "          samples, rather than multiple tags (i.e. no \"/0\" or \"/1\" suffixes).\n",
      "        \n",
      "        To migrate to TF2, please use `tf.summary.audio` instead. Please check\n",
      "        [Migrating tf.summary usage to\n",
      "        TF 2.0](https://www.tensorflow.org/tensorboard/migrate#in_tf_1x) for concrete\n",
      "        steps for migration.\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name  | TF2 Arg Name    | Note                                   |\n",
      "        | :------------ | :-------------- | :------------------------------------- |\n",
      "        | `name`        | `name`          | -                                      |\n",
      "        | `tensor`      | `data`          | Input for this argument now must be    |\n",
      "        :               :                 : three-dimensional `[k, t, c]`, where   :\n",
      "        :               :                 : `k` is the number of audio clips, `t`  :\n",
      "        :               :                 : is the number of frames, and `c` is    :\n",
      "        :               :                 : the number of channels. Two-dimensional:\n",
      "        :               :                 : input is no longer supported.          :\n",
      "        | `sample_rate` | `sample_rate`   | -                                      |\n",
      "        | -             | `step`          | Explicit int64-castable monotonic step |\n",
      "        :               :                 : value. If omitted, this defaults to    :\n",
      "        :               :                 : `tf.summary.experimental.get_step()`.  :\n",
      "        | `max_outputs` | `max_outputs`   | -                                      |\n",
      "        | `collections` | Not Supported   | -                                      |\n",
      "        | `family`      | Removed         | Please use `tf.name_scope` instead to  |\n",
      "        :               :                 : manage summary name prefix.            :\n",
      "        | -             | `encoding`      | Optional constant str for the desired  |\n",
      "        :               :                 : encoding. Check the docs for           :\n",
      "        :               :                 : `tf.summary.audio` for latest supported:\n",
      "        :               :                 : audio formats.                         :\n",
      "        | -             | `description`   | Optional long-form `str` description   |\n",
      "        :               :                 : for the summary. Markdown is supported.:\n",
      "        :               :                 : Defaults to empty.                     :\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    get_summary_description(node_def)\n",
      "        Given a TensorSummary node_def, retrieve its SummaryDescription.\n",
      "        \n",
      "        When a Summary op is instantiated, a SummaryDescription of associated\n",
      "        metadata is stored in its NodeDef. This method retrieves the description.\n",
      "        \n",
      "        Args:\n",
      "          node_def: the node_def_pb2.NodeDef of a TensorSummary op\n",
      "        \n",
      "        Returns:\n",
      "          a summary_pb2.SummaryDescription\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if the node is not a summary op.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Not compatible with eager execution. To write TensorBoard\n",
      "        summaries under eager execution, use `tf.contrib.summary` instead.\n",
      "        @end_compatibility\n",
      "    \n",
      "    histogram(name, values, collections=None, family=None)\n",
      "        Outputs a `Summary` protocol buffer with a histogram.\n",
      "        \n",
      "        Adding a histogram summary makes it possible to visualize your data's\n",
      "        distribution in TensorBoard. You can see a detailed explanation of the\n",
      "        TensorBoard histogram dashboard\n",
      "        [here](https://www.tensorflow.org/get_started/tensorboard_histograms).\n",
      "        \n",
      "        The generated\n",
      "        [`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)\n",
      "        has one summary value containing a histogram for `values`.\n",
      "        \n",
      "        This op reports an `InvalidArgument` error if any value is not finite.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the generated node. Will also serve as a series name in\n",
      "            TensorBoard.\n",
      "          values: A real numeric `Tensor`. Any shape. Values to use to\n",
      "            build the histogram.\n",
      "          collections: Optional list of graph collections keys. The new summary op is\n",
      "            added to these collections. Defaults to `[GraphKeys.SUMMARIES]`.\n",
      "          family: Optional; if provided, used as the prefix of the summary tag name,\n",
      "            which controls the tab name used for display on Tensorboard.\n",
      "        \n",
      "        Returns:\n",
      "          A scalar `Tensor` of type `string`. The serialized `Summary` protocol\n",
      "          buffer.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        For compatibility purposes, when invoked in TF2 where the outermost context is\n",
      "        eager mode, this API will check if there is a suitable TF2 summary writer\n",
      "        context available, and if so will forward this call to that writer instead. A\n",
      "        \"suitable\" writer context means that the writer is set as the default writer,\n",
      "        and there is an associated non-empty value for `step` (see\n",
      "        `tf.summary.SummaryWriter.as_default`, `tf.summary.experimental.set_step` or\n",
      "        alternatively `tf.compat.v1.train.create_global_step`). For the forwarded\n",
      "        call, the arguments here will be passed to the TF2 implementation of\n",
      "        `tf.summary.histogram`, and the return value will be an empty bytestring\n",
      "        tensor, to avoid duplicate summary writing. This forwarding is best-effort and\n",
      "        not all arguments will be preserved.\n",
      "        \n",
      "        To migrate to TF2, please use `tf.summary.histogram` instead. Please check\n",
      "        [Migrating tf.summary usage to\n",
      "        TF 2.0](https://www.tensorflow.org/tensorboard/migrate#in_tf_1x) for concrete\n",
      "        steps for migration.\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name  | TF2 Arg Name    | Note                                   |\n",
      "        | :------------ | :-------------- | :------------------------------------- |\n",
      "        | `name`        | `name`          | -                                      |\n",
      "        | `values`      | `data`          | -                                      |\n",
      "        | -             | `step`          | Explicit int64-castable monotonic step |\n",
      "        :               :                 : value. If omitted, this defaults to    :\n",
      "        :               :                 : `tf.summary.experimental.get_step()`   :\n",
      "        | -             | `buckets`       | Optional positive `int` specifying     |\n",
      "        :               :                 : the histogram bucket number.           :\n",
      "        | `collections` | Not Supported   | -                                      |\n",
      "        | `family`      | Removed         | Please use `tf.name_scope` instead     |\n",
      "        :               :                 : to manage summary name prefix.         :\n",
      "        | -             | `description`   | Optional long-form `str` description   |\n",
      "        :               :                 : for the summary. Markdown is supported.:\n",
      "        :               :                 : Defaults to empty.                     :\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    image(name, tensor, max_outputs=3, collections=None, family=None)\n",
      "        Outputs a `Summary` protocol buffer with images.\n",
      "        \n",
      "        The summary has up to `max_outputs` summary values containing images. The\n",
      "        images are built from `tensor` which must be 4-D with shape `[batch_size,\n",
      "        height, width, channels]` and where `channels` can be:\n",
      "        \n",
      "        *  1: `tensor` is interpreted as Grayscale.\n",
      "        *  3: `tensor` is interpreted as RGB.\n",
      "        *  4: `tensor` is interpreted as RGBA.\n",
      "        \n",
      "        The images have the same number of channels as the input tensor. For float\n",
      "        input, the values are normalized one image at a time to fit in the range\n",
      "        `[0, 255]`.  `uint8` values are unchanged.  The op uses two different\n",
      "        normalization algorithms:\n",
      "        \n",
      "        *  If the input values are all positive, they are rescaled so the largest one\n",
      "           is 255.\n",
      "        \n",
      "        *  If any input value is negative, the values are shifted so input value 0.0\n",
      "           is at 127.  They are then rescaled so that either the smallest value is 0,\n",
      "           or the largest one is 255.\n",
      "        \n",
      "        The `tag` in the outputted Summary.Value protobufs is generated based on the\n",
      "        name, with a suffix depending on the max_outputs setting:\n",
      "        \n",
      "        *  If `max_outputs` is 1, the summary value tag is '*name*/image'.\n",
      "        *  If `max_outputs` is greater than 1, the summary value tags are\n",
      "           generated sequentially as '*name*/image/0', '*name*/image/1', etc.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the generated node. Will also serve as a series name in\n",
      "            TensorBoard.\n",
      "          tensor: A 4-D `uint8` or `float32` `Tensor` of shape `[batch_size, height,\n",
      "            width, channels]` where `channels` is 1, 3, or 4.\n",
      "          max_outputs: Max number of batch elements to generate images for.\n",
      "          collections: Optional list of ops.GraphKeys.  The collections to add the\n",
      "            summary to.  Defaults to [_ops.GraphKeys.SUMMARIES]\n",
      "          family: Optional; if provided, used as the prefix of the summary tag name,\n",
      "            which controls the tab name used for display on Tensorboard.\n",
      "        \n",
      "        Returns:\n",
      "          A scalar `Tensor` of type `string`. The serialized `Summary` protocol\n",
      "          buffer.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        For compatibility purposes, when invoked in TF2 where the outermost context is\n",
      "        eager mode, this API will check if there is a suitable TF2 summary writer\n",
      "        context available, and if so will forward this call to that writer instead. A\n",
      "        \"suitable\" writer context means that the writer is set as the default writer,\n",
      "        and there is an associated non-empty value for `step` (see\n",
      "        `tf.summary.SummaryWriter.as_default`, `tf.summary.experimental.set_step` or\n",
      "        alternatively `tf.compat.v1.train.create_global_step`). For the forwarded\n",
      "        call, the arguments here will be passed to the TF2 implementation of\n",
      "        `tf.summary.image`, and the return value will be an empty bytestring tensor,\n",
      "        to avoid duplicate summary writing. This forwarding is best-effort and not all\n",
      "        arguments will be preserved. Additionally:\n",
      "        \n",
      "        *  The TF2 op does not do any of the normalization steps described above.\n",
      "           Rather than rescaling data that's outside the expected range, it simply\n",
      "           clips it.\n",
      "        *  The TF2 op just outputs the data under a single tag that contains multiple\n",
      "           samples, rather than multiple tags (i.e. no \"/0\" or \"/1\" suffixes).\n",
      "        \n",
      "        To migrate to TF2, please use `tf.summary.image` instead. Please check\n",
      "        [Migrating tf.summary usage to\n",
      "        TF 2.0](https://www.tensorflow.org/tensorboard/migrate#in_tf_1x) for concrete\n",
      "        steps for migration.\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name  | TF2 Arg Name    | Note                                   |\n",
      "        | :------------ | :-------------- | :------------------------------------- |\n",
      "        | `name`        | `name`          | -                                      |\n",
      "        | `tensor`      | `data`          | -                                      |\n",
      "        | -             | `step`          | Explicit int64-castable monotonic step |\n",
      "        :               :                 : value. If omitted, this defaults to    :\n",
      "        :               :                 : `tf.summary.experimental.get_step()`.  :\n",
      "        | `max_outputs` | `max_outputs`   | -                                      |\n",
      "        | `collections` | Not Supported   | -                                      |\n",
      "        | `family`      | Removed         | Please use `tf.name_scope` instead     |\n",
      "        :               :                 : to manage summary name prefix.         :\n",
      "        | -             | `description`   | Optional long-form `str` description   |\n",
      "        :               :                 : for the summary. Markdown is supported.:\n",
      "        :               :                 : Defaults to empty.                     :\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    initialize(graph=None, session=None)\n",
      "        Initializes summary writing for graph execution mode.\n",
      "        \n",
      "        This operation is a no-op when executing eagerly.\n",
      "        \n",
      "        This helper method provides a higher-level alternative to using\n",
      "        `tf.contrib.summary.summary_writer_initializer_op` and\n",
      "        `tf.contrib.summary.graph`.\n",
      "        \n",
      "        Most users will also want to call `tf.compat.v1.train.create_global_step`\n",
      "        which can happen before or after this function is called.\n",
      "        \n",
      "        Args:\n",
      "          graph: A `tf.Graph` or `tf.compat.v1.GraphDef` to output to the writer.\n",
      "            This function will not write the default graph by default. When\n",
      "            writing to an event log file, the associated step will be zero.\n",
      "          session: So this method can call `tf.Session.run`. This defaults\n",
      "            to `tf.compat.v1.get_default_session`.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: If  the current thread has no default\n",
      "            `tf.contrib.summary.SummaryWriter`.\n",
      "          ValueError: If session wasn't passed and no default session.\n",
      "    \n",
      "    merge(inputs, collections=None, name=None)\n",
      "        Merges summaries.\n",
      "        \n",
      "        This op creates a\n",
      "        [`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)\n",
      "        protocol buffer that contains the union of all the values in the input\n",
      "        summaries.\n",
      "        \n",
      "        When the Op is run, it reports an `InvalidArgument` error if multiple values\n",
      "        in the summaries to merge use the same tag.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of `string` `Tensor` objects containing serialized `Summary`\n",
      "            protocol buffers.\n",
      "          collections: Optional list of graph collections keys. The new summary op is\n",
      "            added to these collections. Defaults to `[]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A scalar `Tensor` of type `string`. The serialized `Summary` protocol\n",
      "          buffer resulting from the merging.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: If called with eager mode enabled.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is not compatible with eager execution or `tf.function`. To migrate\n",
      "        to TF2, this API can be omitted entirely, because in TF2 individual summary\n",
      "        ops, like `tf.summary.scalar()`, write directly to the default summary writer\n",
      "        if one is active. Thus, it's not necessary to merge summaries or to manually\n",
      "        add the resulting merged summary output to the writer. See the usage example\n",
      "        shown below.\n",
      "        \n",
      "        For a comprehensive `tf.summary` migration guide, please follow\n",
      "        [Migrating tf.summary usage to\n",
      "        TF 2.0](https://www.tensorflow.org/tensorboard/migrate#in_tf_1x).\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        ```python\n",
      "        dist = tf.compat.v1.placeholder(tf.float32, [100])\n",
      "        tf.compat.v1.summary.histogram(name=\"distribution\", values=dist)\n",
      "        writer = tf.compat.v1.summary.FileWriter(\"/tmp/tf1_summary_example\")\n",
      "        summaries = tf.compat.v1.summary.merge_all()\n",
      "        \n",
      "        sess = tf.compat.v1.Session()\n",
      "        for step in range(100):\n",
      "          mean_moving_normal = np.random.normal(loc=step, scale=1, size=[100])\n",
      "          summ = sess.run(summaries, feed_dict={dist: mean_moving_normal})\n",
      "          writer.add_summary(summ, global_step=step)\n",
      "        ```\n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        ```python\n",
      "        writer = tf.summary.create_file_writer(\"/tmp/tf2_summary_example\")\n",
      "        for step in range(100):\n",
      "          mean_moving_normal = np.random.normal(loc=step, scale=1, size=[100])\n",
      "          with writer.as_default(step=step):\n",
      "            tf.summary.histogram(name='distribution', data=mean_moving_normal)\n",
      "        ```\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    merge_all(key='summaries', scope=None, name=None)\n",
      "        Merges all summaries collected in the default graph.\n",
      "        \n",
      "        Args:\n",
      "          key: `GraphKey` used to collect the summaries.  Defaults to\n",
      "            `GraphKeys.SUMMARIES`.\n",
      "          scope: Optional scope used to filter the summary ops, using `re.match`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          If no summaries were collected, returns None.  Otherwise returns a scalar\n",
      "          `Tensor` of type `string` containing the serialized `Summary` protocol\n",
      "          buffer resulting from the merging.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: If called with eager execution enabled.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is not compatible with eager execution or `tf.function`. To migrate\n",
      "        to TF2, this API can be omitted entirely, because in TF2 individual summary\n",
      "        ops, like `tf.summary.scalar()`, write directly to the default summary writer\n",
      "        if one is active. Thus, it's not necessary to merge summaries or to manually\n",
      "        add the resulting merged summary output to the writer. See the usage example\n",
      "        shown below.\n",
      "        \n",
      "        For a comprehensive `tf.summary` migration guide, please follow\n",
      "        [Migrating tf.summary usage to\n",
      "        TF 2.0](https://www.tensorflow.org/tensorboard/migrate#in_tf_1x).\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        ```python\n",
      "        dist = tf.compat.v1.placeholder(tf.float32, [100])\n",
      "        tf.compat.v1.summary.histogram(name=\"distribution\", values=dist)\n",
      "        writer = tf.compat.v1.summary.FileWriter(\"/tmp/tf1_summary_example\")\n",
      "        summaries = tf.compat.v1.summary.merge_all()\n",
      "        \n",
      "        sess = tf.compat.v1.Session()\n",
      "        for step in range(100):\n",
      "          mean_moving_normal = np.random.normal(loc=step, scale=1, size=[100])\n",
      "          summ = sess.run(summaries, feed_dict={dist: mean_moving_normal})\n",
      "          writer.add_summary(summ, global_step=step)\n",
      "        ```\n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        ```python\n",
      "        writer = tf.summary.create_file_writer(\"/tmp/tf2_summary_example\")\n",
      "        for step in range(100):\n",
      "          mean_moving_normal = np.random.normal(loc=step, scale=1, size=[100])\n",
      "          with writer.as_default(step=step):\n",
      "            tf.summary.histogram(name='distribution', data=mean_moving_normal)\n",
      "        ```\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    scalar(name, tensor, collections=None, family=None)\n",
      "        Outputs a `Summary` protocol buffer containing a single scalar value.\n",
      "        \n",
      "        The generated Summary has a Tensor.proto containing the input Tensor.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the generated node. Will also serve as the series name in\n",
      "            TensorBoard.\n",
      "          tensor: A real numeric Tensor containing a single value.\n",
      "          collections: Optional list of graph collections keys. The new summary op is\n",
      "            added to these collections. Defaults to `[GraphKeys.SUMMARIES]`.\n",
      "          family: Optional; if provided, used as the prefix of the summary tag name,\n",
      "            which controls the tab name used for display on Tensorboard.\n",
      "        \n",
      "        Returns:\n",
      "          A scalar `Tensor` of type `string`. Which contains a `Summary` protobuf.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If tensor has the wrong shape or type.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        For compatibility purposes, when invoked in TF2 where the outermost context is\n",
      "        eager mode, this API will check if there is a suitable TF2 summary writer\n",
      "        context available, and if so will forward this call to that writer instead. A\n",
      "        \"suitable\" writer context means that the writer is set as the default writer,\n",
      "        and there is an associated non-empty value for `step` (see\n",
      "        `tf.summary.SummaryWriter.as_default`, `tf.summary.experimental.set_step` or\n",
      "        alternatively `tf.compat.v1.train.create_global_step`). For the forwarded\n",
      "        call, the arguments here will be passed to the TF2 implementation of\n",
      "        `tf.summary.scalar`, and the return value will be an empty bytestring tensor,\n",
      "        to avoid duplicate summary writing. This forwarding is best-effort and not all\n",
      "        arguments will be preserved.\n",
      "        \n",
      "        To migrate to TF2, please use `tf.summary.scalar` instead. Please check\n",
      "        [Migrating tf.summary usage to\n",
      "        TF 2.0](https://www.tensorflow.org/tensorboard/migrate#in_tf_1x) for concrete\n",
      "        steps for migration. `tf.summary.scalar` can also log training metrics in\n",
      "        Keras, you can check [Logging training metrics in\n",
      "        Keras](https://www.tensorflow.org/tensorboard/scalars_and_keras) for details.\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name  | TF2 Arg Name    | Note                                   |\n",
      "        | :------------ | :-------------- | :------------------------------------- |\n",
      "        | `name`        | `name`          | -                                      |\n",
      "        | `tensor`      | `data`          | -                                      |\n",
      "        | -             | `step`          | Explicit int64-castable monotonic step |\n",
      "        :               :                 : value. If omitted, this defaults to    :\n",
      "        :               :                 : `tf.summary.experimental.get_step()`.  :\n",
      "        | `collections` | Not Supported   | -                                      |\n",
      "        | `family`      | Removed         | Please use `tf.name_scope` instead to  |\n",
      "        :               :                 : manage summary name prefix.            :\n",
      "        | -             | `description`   | Optional long-form `str` description   |\n",
      "        :               :                 : for the summary. Markdown is supported.:\n",
      "        :               :                 : Defaults to empty.                     :\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    tensor_summary(name, tensor, summary_description=None, collections=None, summary_metadata=None, family=None, display_name=None)\n",
      "        Outputs a `Summary` protocol buffer with a serialized tensor.proto.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the generated node. If display_name is not set, it will\n",
      "            also serve as the tag name in TensorBoard. (In that case, the tag\n",
      "            name will inherit tf name scopes.)\n",
      "          tensor: A tensor of any type and shape to serialize.\n",
      "          summary_description: A long description of the summary sequence. Markdown\n",
      "            is supported.\n",
      "          collections: Optional list of graph collections keys. The new summary op is\n",
      "            added to these collections. Defaults to `[GraphKeys.SUMMARIES]`.\n",
      "          summary_metadata: Optional SummaryMetadata proto (which describes which\n",
      "            plugins may use the summary value).\n",
      "          family: Optional; if provided, used as the prefix of the summary tag,\n",
      "            which controls the name used for display on TensorBoard when\n",
      "            display_name is not set.\n",
      "          display_name: A string used to name this data in TensorBoard. If this is\n",
      "            not set, then the node name will be used instead.\n",
      "        \n",
      "        Returns:\n",
      "          A scalar `Tensor` of type `string`. The serialized `Summary` protocol\n",
      "          buffer.\n",
      "    \n",
      "    text(name, tensor, collections=None)\n",
      "        Summarizes textual data.\n",
      "        \n",
      "        Text data summarized via this plugin will be visible in the Text Dashboard\n",
      "        in TensorBoard. The standard TensorBoard Text Dashboard will render markdown\n",
      "        in the strings, and will automatically organize 1d and 2d tensors into tables.\n",
      "        If a tensor with more than 2 dimensions is provided, a 2d subarray will be\n",
      "        displayed along with a warning message. (Note that this behavior is not\n",
      "        intrinsic to the text summary api, but rather to the default TensorBoard text\n",
      "        plugin.)\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the generated node. Will also serve as a series name in\n",
      "            TensorBoard.\n",
      "          tensor: a string-type Tensor to summarize.\n",
      "          collections: Optional list of ops.GraphKeys.  The collections to add the\n",
      "            summary to.  Defaults to [_ops.GraphKeys.SUMMARIES]\n",
      "        \n",
      "        Returns:\n",
      "          A TensorSummary op that is configured so that TensorBoard will recognize\n",
      "          that it contains textual data. The TensorSummary is a scalar `Tensor` of\n",
      "          type `string` which contains `Summary` protobufs.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If tensor has the wrong type.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        For compatibility purposes, when invoked in TF2 where the outermost context is\n",
      "        eager mode, this API will check if there is a suitable TF2 summary writer\n",
      "        context available, and if so will forward this call to that writer instead. A\n",
      "        \"suitable\" writer context means that the writer is set as the default writer,\n",
      "        and there is an associated non-empty value for `step` (see\n",
      "        `tf.summary.SummaryWriter.as_default`, `tf.summary.experimental.set_step` or\n",
      "        alternatively `tf.compat.v1.train.create_global_step`). For the forwarded\n",
      "        call, the arguments here will be passed to the TF2 implementation of\n",
      "        `tf.summary.text`, and the return value will be an empty bytestring tensor, to\n",
      "        avoid duplicate summary writing. This forwarding is best-effort and not all\n",
      "        arguments will be preserved.\n",
      "        \n",
      "        To migrate to TF2, please use `tf.summary.text` instead. Please check\n",
      "        [Migrating tf.summary usage to\n",
      "        TF 2.0](https://www.tensorflow.org/tensorboard/migrate#in_tf_1x) for concrete\n",
      "        steps for migration.\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name  | TF2 Arg Name    | Note                                   |\n",
      "        | :------------ | :-------------- | :------------------------------------- |\n",
      "        | `name`        | `name`          | -                                      |\n",
      "        | `tensor`      | `data`          | -                                      |\n",
      "        | -             | `step`          | Explicit int64-castable monotonic step |\n",
      "        :               :                 : value. If omitted, this defaults to    :\n",
      "        :               :                 : `tf.summary.experimental.get_step()`.  :\n",
      "        | `collections` | Not Supported   | -                                      |\n",
      "        | -             | `description`   | Optional long-form `str` description   |\n",
      "        :               :                 : for the summary. Markdown is supported.:\n",
      "        :               :                 : Defaults to empty.                     :\n",
      "        \n",
      "        @end_compatibility\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Event', 'FileWriter', 'FileWriterCache', 'SessionLog', 'Su...\n",
      "\n",
      "FILE\n",
      "    /home/analyst/dlenv/lib/python3.11/site-packages/tensorflow/_api/v2/compat/v1/summary/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4157e26f-17a7-48b5-a903-a28b0df0f903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mrun-2024-02-06-21-07-40\u001b[0m/  \u001b[01;34mrun-2024-02-06-21-19-57\u001b[0m/  \u001b[01;34mrun-2024-02-06-21-48-05\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls tf_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edd0f518-7457-4a93-bb21-b9e387e12d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.out.tfevents.1707256086.588a547f6c7a\n",
      "events.out.tfevents.1707256124.588a547f6c7a\n"
     ]
    }
   ],
   "source": [
    "%ls {logd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "757e6a1c-237a-457e-a492-cce8f17a6252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.summary.writer.writer.FileWriter at 0x7f325bdd4dd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a881fea6-8835-4ce0-bc7d-a4f8fc387084",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7c1cff8-8a44-49df-aee2-6e493468cbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 932\n",
      "drwxr-xr-x 1 analyst analyst    512 Feb  6 21:48 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
      "drwxr-xr-x 1 analyst analyst    512 Feb  6 21:48 \u001b[01;34m..\u001b[0m/\n",
      "-rw-r--r-- 1 analyst analyst  18039 Feb  6 21:48 events.out.tfevents.1707256086.588a547f6c7a\n",
      "-rw-r--r-- 1 analyst analyst 921012 Feb  6 21:54 events.out.tfevents.1707256124.588a547f6c7a\n"
     ]
    }
   ],
   "source": [
    "%ls -la {logd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f375a726-0589-4256-bcbd-9d10a2c24d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=http://localhost:6006/ style=\"width: 1000px; height: 600px;\"></>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=http://localhost:6006/ style=\"width: 1000px; height: 600px;\"></>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f44d65-9444-4771-9239-4fc0ba4e2fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a2828-a6a3-418e-bbe5-eeed7edd1cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40c343-347a-4f73-a778-d4fba1a0d562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0bfad3-c150-491c-bb1b-c45ccd8f0226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4c4b1-bd1d-4d1e-b77a-328a61a7f60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83571039-8905-4eae-94d9-db6dc5e3e179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa14ef-9876-46e1-a8af-d23272b43ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
